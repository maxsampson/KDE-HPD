# -*- coding: utf-8 -*-
"""CHR_Bowtie

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1EI-RNySnpeA_o_QEI2CNl2FsEJUQAX-n
"""

import os
import sys
import pdb
import torch

import numpy as np
import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt
from tqdm.autonotebook import tqdm
from sklearn.model_selection import train_test_split

# sys.path.insert(0,'/content/chr/chr')

def plot_func(x, y, quantiles=None, quantile_labels=None, max_show=5000,
              shade_color="", method_name="", title="", filename=None, save_figures=False):

    """ Scatter plot of (x,y) points along with the constructed prediction interval

    Parameters
    ----------
    x : numpy array, corresponding to the feature of each of the n samples
    y : numpy array, target response variable (length n)
    quantiles : numpy array, the estimated prediction. It may be the conditional mean,
                or low and high conditional quantiles.
    shade_color : string, desired color of the prediciton interval
    method_name : string, name of the method
    title : string, the title of the figure
    filename : sting, name of the file to save the figure
    save_figures : boolean, save the figure (True) or not (False)

    """

    x_ = x[:max_show]
    y_ = y[:max_show]
    if quantiles is not None:
        quantiles = quantiles[:max_show]

    fig = plt.figure()
    inds = np.argsort(np.squeeze(x_))
    plt.plot(x_[inds], y_[inds], 'k.', alpha=.2, markersize=10, fillstyle='none')

    if quantiles is not None:
        num_quantiles = quantiles.shape[1]
    else:
        num_quantiles = 0

    if quantile_labels is None:
        pred_labels = ["NA"] * num_quantiles
    for k in range(num_quantiles):
        label_txt = 'Quantile {q}'.format(q=quantile_labels[k])
        plt.plot(x_[inds], quantiles[inds,k], '-', lw=2, alpha=0.75, label=label_txt)

    plt.ylim([-20, 25])
    plt.xlabel('$X$')
    plt.ylabel('$Y$')
    plt.legend(bbox_to_anchor=(1.01, 1), loc='upper left')
    plt.title(title)
    if save_figures and (filename is not None):
        plt.savefig(filename, bbox_inches='tight', dpi=300)

    plt.show()

import coverage
np.random.seed(123)

# Generate samples
# Define parameters
n = 1050
ntrain = 500
ncal = 500

# Generate random values
x_train = np.random.uniform(-5, 5, ntrain)
error_train = np.random.normal(0, np.abs(x_train))
y_train = 5 + 2 * x_train + error_train
x_cal = np.random.uniform(-5, 5, ncal)
error_cal = np.random.normal(0, np.abs(x_cal))
y_cal = 5 + 2 * x_cal + error_cal
x_out = np.random.uniform(-5, 5, 50)
error_out = np.random.normal(0, np.abs(x_out))
y_out = 5 + 2 * x_out + error_out

# Create data frames for training, calibration, and out-of-sample prediction data

# Generate test samples
# Plot data
split_color = 'tomato'
local_color = 'gray'
cqr_color = 'lightblue'

# maximal number of testpoints to plot
max_show = 1000

# display the test data in full range (including the outliers)
fig = plt.figure()
plt.plot(x_train, y_train, 'k.', alpha = 0.3, markersize=10,
         fillstyle='none', label=u'Observations')
plt.legend()
plt.xlabel('$X$')
plt.ylabel('$Y$')
plt.title('Test data (visualize outliers)')

#!pip install quantile-forest
from quantile_forest import RandomForestQuantileRegressor

class QRF:
    """ Fit a random forest (conditional quantile) to training data
    """
    def __init__(self, quantiles, min_samples_leaf=5, n_estimators=100, n_jobs=1,
                 random_state=0, verbose=False):
        """ Initialization
        Parameters
        ----------
        quantiles : numpy array of quantile levels (q), each in the range (0,1)
        num_features : integer, input signal dimension (p)
        random_state : integer, seed used in quantile random forests
        """

        self.device = 'cpu'
        # Store input (sort the quantiles)
        self.quantiles = torch.from_numpy(np.sort(quantiles)).float().to(self.device)
        # Define RF model
        self.model = RandomForestQuantileRegressor(random_state=random_state,
                                                   min_samples_leaf=min_samples_leaf,
                                                   n_estimators=n_estimators,
                                                   n_jobs=n_jobs, verbose=verbose)

    def fit(self, X, Y, return_loss=None):
        #warnings.filterwarnings("ignore", category=FutureWarning)
        self.model.fit(X, Y)
        #warnings.filterwarnings("default", category=FutureWarning)
        return 0

    def predict(self, X):
        """ Estimate the label given the features
        Parameters
        ----------
        x : numpy array of training features (nXp)
        Returns
        -------
        ret_val : numpy array of predicted labels (n)
        """
        quantiles = self.quantiles.cpu()
        ret_val = np.zeros((X.shape[0], len(quantiles)))
        print("Predicting RF quantiles:")
        for i in tqdm(range(len(quantiles))):
            ret_val[:,i] = self.model.predict(X,quantiles=quantiles[i].tolist())
        return ret_val

    def get_quantiles(self):
        return self.quantiles.cpu().numpy()

from histogram import Histogram
from utils import plot_histogram
from grey_boxes import HistogramAccumulator
from utils import evaluate_predictions
from methods import CHR
from pytictoc import TicToc

'''
## bowtie
coverage = np.empty((0, 1), dtype=np.float32)
length = np.empty((0, 1), dtype=np.float32)
np.random.seed(6)
t = TicToc()  # create instance of class
start_time= t.tic() #start timer
for i in range(1000):
    # Generate samples
    n = 1050
    ntrain = 500
    ncal = 500

    # Generate random values
    x_train = np.random.uniform(-5, 5, ntrain)
    error_train = np.random.normal(0, np.abs(x_train))
    y_train = 5 + 2 * x_train + error_train
    x_cal = np.random.uniform(-5, 5, ncal)
    error_cal = np.random.normal(0, np.abs(x_cal))
    y_cal = 5 + 2 * x_cal + error_cal
    x_out = np.random.uniform(-5, 5, 50)
    error_out = np.random.normal(0, np.abs(x_out))
    y_out = 5 + 2 * x_out + error_out
    grid_quantiles = np.arange(0.01,0.99,0.01)
    # Initialize quantile forest
    bbox = QRF(quantiles = grid_quantiles)

    bbox.fit(x_train.reshape(-1, 1), y_train)

    # Predict the quantiles
    y_pred = bbox.predict(X=x_cal.reshape(-1, 1))

    # Discrete grid for density estimator
    grid_histogram = np.arange(y_cal.min(), y_cal.max(),0.25)

    # Initialize conditional density estimator
    hist = Histogram(grid_quantiles, grid_histogram)
    # Estimate conditional density for test points
    histogram_test = hist.compute_histogram(y_pred, y_cal.min(), y_cal.max(), 0.1)

    # Initialize density accumulator (grey-box)
    accumulator = HistogramAccumulator(histogram_test, grid_histogram, alpha=0.1, delta_alpha=0.01)

    # Desired level
    alpha = 0.1

    # Generate noise for randomization
    epsilon = np.random.uniform(low=0.0, high=1.0, size=x_cal.shape[0])

    # Compute itervals
    S, bands = accumulator.predict_intervals(alpha, epsilon=epsilon)

    chr = CHR(bbox, ymin=y_cal.min(), ymax=y_cal.max(), y_steps=200, delta_alpha=0.001, randomize=True)
    chr.calibrate(x_cal.reshape(-1, 1), y_cal, alpha)

    bands = chr.predict(x_out.reshape(-1, 1))




    test = evaluate_predictions(bands, y_out, X=x_out.reshape(-1, 1))
    temp_cov = test.Coverage.values.reshape(-1, 1)
    temp_len = test.Length.values.reshape(-1, 1)
    coverage = np.concatenate((coverage, temp_cov), 0)
    length = np.concatenate((length, temp_len), 0)
    if i % 50 == 0:
        print(i)
end_time = t.toc()
print("end_time", end_time)

import math
from math import sqrt
coverage.mean()
length.mean()

coverage.std() / sqrt(1000)
length.std() / sqrt(1000)

#np.savetxt(fname="coverage_bowtie.csv", delimiter=",", X=coverage)
#np.savetxt(fname="length_bowtie.csv", delimiter=",", X=length)
'''
## unimodal and symmetric
coverage_norm = np.empty((0, 1), dtype=np.float32)
length_norm = np.empty((0, 1), dtype=np.float32)
np.random.seed(6)
t = TicToc()  # create instance of class
start_time= t.tic() #start timer
for i in range(1000):
    # Generate samples
    n = 1050
    ntrain = 500
    ncal = 500

    # Generate random values
    x_train = np.random.uniform(-5, 5, ntrain)
    error_train = np.random.normal(0, 1, ntrain)
    y_train = 5 + 2 * x_train + error_train
    x_cal = np.random.uniform(-5, 5, ncal)
    error_cal = np.random.normal(0, 1, ncal)
    y_cal = 5 + 2 * x_cal + error_cal
    x_out = np.random.uniform(-5, 5, 50)
    error_out = np.random.normal(0, 1, 50)
    y_out = 5 + 2 * x_out + error_out
    grid_quantiles = np.arange(0.01,0.99,0.01)
    # Initialize quantile forest
    bbox = QRF(quantiles = grid_quantiles)

    bbox.fit(x_train.reshape(-1, 1), y_train)

    # Predict the quantiles
    y_pred = bbox.predict(X=x_cal.reshape(-1, 1))

    # Discrete grid for density estimator
    grid_histogram = np.arange(y_cal.min(), y_cal.max(),0.25)

    # Initialize conditional density estimator
    hist = Histogram(grid_quantiles, grid_histogram)
    # Estimate conditional density for test points
    histogram_test = hist.compute_histogram(y_pred, y_cal.min(), y_cal.max(), 0.1)

    # Initialize density accumulator (grey-box)
    accumulator = HistogramAccumulator(histogram_test, grid_histogram, alpha=0.1, delta_alpha=0.01)

    # Desired level
    alpha = 0.1

    # Generate noise for randomization
    epsilon = np.random.uniform(low=0.0, high=1.0, size=x_cal.shape[0])

    # Compute itervals
    S, bands = accumulator.predict_intervals(alpha, epsilon=epsilon)

    chr = CHR(bbox, ymin=y_cal.min(), ymax=y_cal.max(), y_steps=200, delta_alpha=0.001, randomize=True)
    chr.calibrate(x_cal.reshape(-1, 1), y_cal, alpha)

    bands = chr.predict(x_out.reshape(-1, 1))




    test = evaluate_predictions(bands, y_out, X=x_out.reshape(-1, 1))
    temp_cov = test.Coverage.values.reshape(-1, 1)
    temp_len = test.Length.values.reshape(-1, 1)
    coverage_norm = np.concatenate((coverage_norm, temp_cov), 0)
    length_norm = np.concatenate((length_norm, temp_len), 0)
    if i % 50 == 0:
        print(i)
end_time_normal = t.toc()

print("end_time", end_time_normal)
np.savetxt(fname="coverage_norm.csv", delimiter=",", X=coverage_norm)
np.savetxt(fname="length_norm.csv", delimiter=",", X=length_norm)


coverage_norm.mean()
length_norm.mean()

coverage_norm.std() / sqrt(1000)
length_norm.std() / sqrt(1000)

## unimodal and skewed
coverage_skew = np.empty((0, 1), dtype=np.float32)
length_skew = np.empty((0, 1), dtype=np.float32)
np.random.seed(6)
t = TicToc()  # create instance of class
start_time= t.tic() #start timer
for i in range(1000):
    # Generate samples
    n = 1050
    ntrain = 500
    ncal = 500

    # Generate random values
    x_train = np.random.uniform(-5, 5, ntrain)
    error_train = np.random.gamma(7.5, 1, ntrain)
    y_train = 5 + 2 * x_train + error_train
    x_cal = np.random.uniform(-5, 5, ncal)
    error_cal = np.random.gamma(7.5, 1, ncal)
    y_cal = 5 + 2 * x_cal + error_cal
    x_out = np.random.uniform(-5, 5, 50)
    error_out = np.random.gamma(7.5, 1, 50)
    y_out = 5 + 2 * x_out + error_out
    grid_quantiles = np.arange(0.01,0.99,0.01)
    # Initialize quantile forest
    bbox = QRF(quantiles = grid_quantiles)

    bbox.fit(x_train.reshape(-1, 1), y_train)

    # Predict the quantiles
    y_pred = bbox.predict(X=x_cal.reshape(-1, 1))

    # Discrete grid for density estimator
    grid_histogram = np.arange(y_cal.min(), y_cal.max(),0.25)

    # Initialize conditional density estimator
    hist = Histogram(grid_quantiles, grid_histogram)
    # Estimate conditional density for test points
    histogram_test = hist.compute_histogram(y_pred, y_cal.min(), y_cal.max(), 0.1)

    # Initialize density accumulator (grey-box)
    accumulator = HistogramAccumulator(histogram_test, grid_histogram, alpha=0.1, delta_alpha=0.01)

    # Desired level
    alpha = 0.1

    # Generate noise for randomization
    epsilon = np.random.uniform(low=0.0, high=1.0, size=x_cal.shape[0])

    # Compute itervals
    S, bands = accumulator.predict_intervals(alpha, epsilon=epsilon)

    chr = CHR(bbox, ymin=y_cal.min(), ymax=y_cal.max(), y_steps=200, delta_alpha=0.001, randomize=True)
    chr.calibrate(x_cal.reshape(-1, 1), y_cal, alpha)

    bands = chr.predict(x_out.reshape(-1, 1))




    test = evaluate_predictions(bands, y_out, X=x_out.reshape(-1, 1))
    temp_cov = test.Coverage.values.reshape(-1, 1)
    temp_len = test.Length.values.reshape(-1, 1)
    coverage_skew = np.concatenate((coverage_skew, temp_cov), 0)
    length_skew = np.concatenate((length_skew, temp_len), 0)
    if i % 50 == 0:
        print(i)
end_time_skew = t.toc()

print("end_time", end_time_skew)
np.savetxt(fname="coverage_skew.csv", delimiter=",", X=coverage_skew)
np.savetxt(fname="length_skew.csv", delimiter=",", X=length_skew)


coverage_skew.mean()
length_skew.mean()

coverage_skew.std() / sqrt(1000)
length_skew.std() / sqrt(1000)

## heteroskedastic
coverage_het = np.empty((0, 1), dtype=np.float32)
length_het = np.empty((0, 1), dtype=np.float32)
np.random.seed(6)
t = TicToc()  # create instance of class
start_time= t.tic() #start timer
for i in range(1000):
    # Generate samples
    n = 1050
    ntrain = 500
    ncal = 500

    # Generate random values
    x_train = np.random.uniform(-5, 5, ntrain)
    error_train = np.random.gamma(1 + 2 * np.abs(x_train), 1 / (1 + 2 * np.abs(x_train)))
    y_train = 5 + 2 * x_train + error_train
    x_cal = np.random.uniform(-5, 5, ncal)
    error_cal = np.random.gamma(1 + 2 * np.abs(x_cal), 1 / (1 + 2 * np.abs(x_cal)))
    y_cal = 5 + 2 * x_cal + error_cal
    x_out = np.random.uniform(-5, 5, 50)
    error_out = np.random.gamma(1 + 2 * np.abs(x_out), 1 / (1 + 2 * np.abs(x_out)))
    y_out = 5 + 2 * x_out + error_out
    grid_quantiles = np.arange(0.01,0.99,0.01)
    # Initialize quantile forest
    bbox = QRF(quantiles = grid_quantiles)

    bbox.fit(x_train.reshape(-1, 1), y_train)

    # Predict the quantiles
    y_pred = bbox.predict(X=x_cal.reshape(-1, 1))

    # Discrete grid for density estimator
    grid_histogram = np.arange(y_cal.min(), y_cal.max(),0.25)

    # Initialize conditional density estimator
    hist = Histogram(grid_quantiles, grid_histogram)
    # Estimate conditional density for test points
    histogram_test = hist.compute_histogram(y_pred, y_cal.min(), y_cal.max(), 0.1)

    # Initialize density accumulator (grey-box)
    accumulator = HistogramAccumulator(histogram_test, grid_histogram, alpha=0.1, delta_alpha=0.01)

    # Desired level
    alpha = 0.1

    # Generate noise for randomization
    epsilon = np.random.uniform(low=0.0, high=1.0, size=x_cal.shape[0])

    # Compute itervals
    S, bands = accumulator.predict_intervals(alpha, epsilon=epsilon)

    chr = CHR(bbox, ymin=y_cal.min(), ymax=y_cal.max(), y_steps=200, delta_alpha=0.001, randomize=True)
    chr.calibrate(x_cal.reshape(-1, 1), y_cal, alpha)

    bands = chr.predict(x_out.reshape(-1, 1))




    test = evaluate_predictions(bands, y_out, X=x_out.reshape(-1, 1))
    temp_cov = test.Coverage.values.reshape(-1, 1)
    temp_len = test.Length.values.reshape(-1, 1)
    coverage_het = np.concatenate((coverage_het, temp_cov), 0)
    length_het = np.concatenate((length_het, temp_len), 0)
    if i % 50 == 0:
        print(i)
end_time_het = t.toc()

print("end_time", end_time_het)
np.savetxt(fname="coverage_het.csv", delimiter=",", X=coverage_het)
np.savetxt(fname="length_het.csv", delimiter=",", X=length_het)


coverage_het.mean()
length_het.mean()

coverage_het.std() / sqrt(1000)
length_het.std() / sqrt(1000)

## bimodal
coverage_bi = np.empty((0, 1), dtype=np.float32)
length_bi = np.empty((0, 1), dtype=np.float32)
np.random.seed(6)
t = TicToc()  # create instance of class
start_time= t.tic() #start timer
for i in range(1000):
    # Generate samples
    n = 1050
    ntrain = 500
    ncal = 500

    # Generate random values
    x_train = np.random.uniform(-5, 5, ntrain)
    error1 = np.random.normal(loc=-6, scale=1, size=ntrain//2)
    error2 = np.random.normal(loc=6, scale=1, size=ntrain//2)

    # Combine and shuffle errors
    error_train = np.concatenate([error1, error2])
    np.random.shuffle(error_train)  # Equivalent to `sample(n, n, replace = FALSE)`
    y_train = 5 + 2 * x_train + error_train
    x_cal = np.random.uniform(-5, 5, ncal)
    error1 = np.random.normal(loc=-6, scale=1, size=ncal//2)
    error2 = np.random.normal(loc=6, scale=1, size=ncal//2)

    # Combine and shuffle errors
    error_cal = np.concatenate([error1, error2])
    np.random.shuffle(error_cal)  # Equivalent to `sample(n, n, replace = FALSE)`
    y_cal = 5 + 2 * x_cal + error_cal
    x_out = np.random.uniform(-5, 5, 50)
    error1 = np.random.normal(loc=-6, scale=1, size=50//2)
    error2 = np.random.normal(loc=6, scale=1, size=50//2)

    # Combine and shuffle errors
    error_out = np.concatenate([error1, error2])
    np.random.shuffle(error_out)  # Equivalent to `sample(n, n, replace = FALSE)`
    y_out = 5 + 2 * x_out + error_out
    grid_quantiles = np.arange(0.01,0.99,0.01)
    # Initialize quantile forest
    bbox = QRF(quantiles = grid_quantiles)

    bbox.fit(x_train.reshape(-1, 1), y_train)

    # Predict the quantiles
    y_pred = bbox.predict(X=x_cal.reshape(-1, 1))

    # Discrete grid for density estimator
    grid_histogram = np.arange(y_cal.min(), y_cal.max(),0.25)

    # Initialize conditional density estimator
    hist = Histogram(grid_quantiles, grid_histogram)
    # Estimate conditional density for test points
    histogram_test = hist.compute_histogram(y_pred, y_cal.min(), y_cal.max(), 0.1)

    # Initialize density accumulator (grey-box)
    accumulator = HistogramAccumulator(histogram_test, grid_histogram, alpha=0.1, delta_alpha=0.01)

    # Desired level
    alpha = 0.1

    # Generate noise for randomization
    epsilon = np.random.uniform(low=0.0, high=1.0, size=x_cal.shape[0])

    # Compute itervals
    S, bands = accumulator.predict_intervals(alpha, epsilon=epsilon)

    chr = CHR(bbox, ymin=y_cal.min(), ymax=y_cal.max(), y_steps=200, delta_alpha=0.001, randomize=True)
    chr.calibrate(x_cal.reshape(-1, 1), y_cal, alpha)

    bands = chr.predict(x_out.reshape(-1, 1))




    test = evaluate_predictions(bands, y_out, X=x_out.reshape(-1, 1))
    temp_cov = test.Coverage.values.reshape(-1, 1)
    temp_len = test.Length.values.reshape(-1, 1)
    coverage_bi = np.concatenate((coverage_bi, temp_cov), 0)
    length_bi = np.concatenate((length_bi, temp_len), 0)
    if i % 50 == 0:
        print(i)
end_time_bi = t.toc()

print("end_time", end_time_bi)
np.savetxt(fname="coverage_bi.csv", delimiter=",", X=coverage_bi)
np.savetxt(fname="length_bi.csv", delimiter=",", X=length_bi)

coverage_bi.mean()
length_bi.mean()
from math import sqrt
coverage_bi.std() / sqrt(1000)
length_bi.std() / sqrt(1000)

print(end_time_bi)
