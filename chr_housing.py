# -*- coding: utf-8 -*-
"""CHR_Housing

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1ExwvgYQ-XKIlBBWUd0z2Fn6waHcTicy_
"""

!git clone https://github.com/msesia/chr.git
!pip install quantile-forest

import os
import sys
import pdb
import torch

import numpy as np
import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt
from tqdm.autonotebook import tqdm
from sklearn.model_selection import train_test_split

sys.path.insert(0,'/content/chr/chr')
from quantile_forest import RandomForestQuantileRegressor

class QRF:
    """ Fit a random forest (conditional quantile) to training data
    """
    def __init__(self, quantiles, min_samples_leaf=5, n_estimators=100, n_jobs=1,
                 random_state=0, verbose=False):
        """ Initialization
        Parameters
        ----------
        quantiles : numpy array of quantile levels (q), each in the range (0,1)
        num_features : integer, input signal dimension (p)
        random_state : integer, seed used in quantile random forests
        """

        self.device = 'cpu'
        # Store input (sort the quantiles)
        self.quantiles = torch.from_numpy(np.sort(quantiles)).float().to(self.device)
        # Define RF model
        self.model = RandomForestQuantileRegressor(random_state=random_state,
                                                   min_samples_leaf=min_samples_leaf,
                                                   n_estimators=n_estimators,
                                                   n_jobs=n_jobs, verbose=verbose)

    def fit(self, X, Y, return_loss=None):
        #warnings.filterwarnings("ignore", category=FutureWarning)
        self.model.fit(X, Y)
        #warnings.filterwarnings("default", category=FutureWarning)
        return 0

    def predict(self, X):
        """ Estimate the label given the features
        Parameters
        ----------
        x : numpy array of training features (nXp)
        Returns
        -------
        ret_val : numpy array of predicted labels (n)
        """
        quantiles = self.quantiles.cpu()
        ret_val = np.zeros((X.shape[0], len(quantiles)))
        print("Predicting RF quantiles:")
        for i in tqdm(range(len(quantiles))):
            ret_val[:,i] = self.model.predict(X,quantiles=quantiles[i].tolist())
        return ret_val

    def get_quantiles(self):
        return self.quantiles.cpu().numpy()

from histogram import Histogram
from utils import plot_histogram
from grey_boxes import HistogramAccumulator
from utils import evaluate_predictions
from methods import CHR

from google.colab import files

# Upload file
# uploaded = files.upload() #only necessary if you are working on a remote server
## housing
realestate = pd.read_csv("realestate.txt", delimiter="\t")  # Adjust delimiter if needed

coverage = np.empty((0, 1), dtype=np.float32)
length = np.empty((0, 1), dtype=np.float32)
len_med = np.empty((0, 1), dtype=np.float32)
coverage_air = np.empty((0, ), dtype=np.float32)
coverage_noair = np.empty((0, ), dtype=np.float32)
coverage_large = np.empty((0, ), dtype=np.float32)
np.random.seed(1)
for i in range(200):
    # Generate shuffled indices
    indices = np.random.permutation(len(realestate))

    # Shuffle the dataset
    dat = realestate.iloc[indices]

    # Split the data into train, calibration, and out-of-sample test sets
    dat_train = dat.iloc[:200]  # First 200 samples
    dat_cal = dat.iloc[200:300]  # Next 100 samples
    dat_out = dat.iloc[300:]  # Remaining samples
    # Generate random values
    x_train = dat_train[['Air', 'SqFeet']]
    y_train = dat_train['SalePrice']
    x_cal = dat_cal[['Air', 'SqFeet']]
    y_cal = dat_cal['SalePrice']
    x_out = dat_out[['Air', 'SqFeet']]
    y_out = dat_out['SalePrice']

    # Define grid of quantiles
    grid_quantiles = np.arange(0.01,0.99,0.01)
    # Initialize quantile forest
    bbox = QRF(quantiles = grid_quantiles)

    bbox.fit(x_train, y_train)

    # Predict the quantiles
    y_pred = bbox.predict(X=x_cal)

    # Discrete grid for density estimator
    grid_histogram = np.arange(y_cal.min(), y_cal.max(),0.25)

    # Initialize conditional density estimator
    hist = Histogram(grid_quantiles, grid_histogram)
    # Estimate conditional density for test points
    histogram_test = hist.compute_histogram(y_pred, y_cal.min(), y_cal.max(), 0.1)

    # Initialize density accumulator (grey-box)
    accumulator = HistogramAccumulator(histogram_test, grid_histogram, alpha=0.1, delta_alpha=0.01)

    # Desired level
    alpha = 0.1

    # Generate noise for randomization
    epsilon = np.random.uniform(low=0.0, high=1.0, size=x_cal.shape[0])

    # Compute itervals
    S, bands = accumulator.predict_intervals(alpha, epsilon=epsilon)

    chr = CHR(bbox, ymin=y_cal.min(), ymax=y_cal.max(), y_steps=200, delta_alpha=0.001, randomize=True)
    chr.calibrate(x_cal, y_cal, alpha)

    bands = chr.predict(x_out)


    pred_l = np.min(bands, 1)
    pred_h = np.max(bands, 1)
    cover = (y_out>=pred_l)*(y_out<=pred_h)
    cover = cover.values

    temp_cov = np.mean(cover).reshape(-1, 1)
    temp_len = np.mean(pred_h-pred_l).reshape(-1, 1)
    temp_med = np.median(pred_h-pred_l).reshape(-1, 1)
    coverage = np.concatenate((coverage, temp_cov), 0)
    length = np.concatenate((length, temp_len), 0)
    len_med = np.concatenate((len_med, temp_med), 0)

    boolean_air = dat_out['Air'] == 1
    boolean_noair = dat_out['Air'] == 0
    boolean_large = dat_out['SalePrice'] > 335
    coverage_air = np.concatenate((coverage_air, cover[boolean_air]), 0)  # For matching 'Air' == 1
    coverage_noair = np.concatenate((coverage_noair, cover[boolean_noair]), 0)
    coverage_large = np.concatenate((coverage_large, cover[boolean_large]), 0)
    if i % 10 == 0:
        print(i)

import math
test = np.concatenate((coverage_air, coverage_noair), 0)
test = test.reshape(-1, 1)
np.mean(test)
np.std(test) / math.sqrt(200)
np.mean(coverage)
np.std(coverage) / math.sqrt(200)
np.mean(length)
np.std(length) / math.sqrt(200)
np.median(len_med)
np.std(len_med) / math.sqrt(200)
np.mean(coverage_air)
np.std(coverage_air) / math.sqrt(200)
np.mean(coverage_noair)
np.std(coverage_noair) / math.sqrt(200)
np.mean(coverage_large)
np.std(coverage_large) / math.sqrt(200)